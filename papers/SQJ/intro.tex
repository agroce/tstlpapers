\section{Introduction}

Software test automation can be divided into two aspects:  automated execution
and determination of results for existing, human-created tests, and
the automatic generation of tests, based on some definition of valid
tests.  Both are critical for effective, efficient software testing,
but only automatic generation offers the promise of discovering faults
without human determination that a particular execution scenario has
the potential to behave incorrectly.
This paper presents a case study of applying a new automated test case
generation language and toolchain to a large, real-world software system.
The test effort has been driven and directed not by a software testing
researcher (as is the usual case), but by a domain expert in the
Geographic Information System (GIS)
Software Under Test (SUT).  In the process, multiple faults and
undocumented restrictions of the API under test have been discovered.

\subsection{Testing Esri ArcPy}


Esri is the single largest GIS software vendor, with about 40\% of
global market share.  Esri's ArcGIS tools are extremely widely used
for GIS analysis, in government, scientific research, commercial
enterprises, and education.  Automation of complex GIS analysis and
data management is essential, and Esri has long provided tools for
programming their GIS software tools.  The newest such method,
introduced in ArcGIS 10.0, is a Python site-package, ArcPy
\cite{ArcPy}.  ArcPy is a complex library, with dozens of classes and
hundreds of functions distributed over a variety of of toolboxes.
Most of the code executed in carrying out ArcPy functions is the code
for the ArcGIS engine itself.  This source code, written in C++, is
not available.  The source code for the latest version (10.3) of the
Python site-package alone, however, which interfaces with the ArcGIS
engine, is over 50,000 lines of code.  This is a very large system
(especially given the compactness of Python code), comparable in size
to the largest software systems previously tested using automated test
generation, such as core Java and Apache libraries
\cite{FA11,Pacheco}.

In order to improve the reliability of ArcPy, we are developing a
framework for automated testing of ArcPy itself, as well as libraries
based on ArcPy.  The source code for defining the structure of ArcPy
tests, written in the TSTL\footnote{TSTL stands for Template Scripting
  Testing Language.}\cite{NFM15,ISSTA14,tstl} domain-specific
language \cite{Fow10} for testing, is already more than six times as
large as the next-largest such definition previously implemented in
TSTL, even though the harness so far only includes a small portion of ArcPy
API (Application Program Interface) calls. The first stage of testing has resulted in discovery of
multiple faults in ArcPy/ArcGIS, and has required modifications to the
TSTL language and, especially, to the toolchain supporting test replay,
debugging, and test case understanding.

One of the contributions of this paper is a more in-depth discussion
of the problems, challenges, and tool utility aspects of testing
software than is typical in most research papers in the field.  Such
papers are (understandably) typically focused on novel algorithms or
empirical evaluations of known methods, rather than the practical aspects of finding
and understanding faults in a real-world software system.


\subsection{Automated Testing for the Rest of the World}

Previous work on automated testing for APIs has been largely carried
out by software testing researchers only, or (at most) by software
testing researchers working with individuals who are primarily
software developers.  This paper presents work largely directed by
the first author, who is not a software developer by
profession or education, but a GIS analyst.  

The problem of end-user testing
\cite{burnettEUSE,Silos,rothermelTOSEM} is known to be difficult.
Previous work has focused on end-users of systems that are not
traditional programming languages: e.g. spreadsheets \cite{rothermelTOSEM}, visual
languages, or machine-learning systems \cite{OnlyOracle}.  This paper aims to describe a
case study in how a user who is familiar with a software library but
not expert in software testing techniques can use (and adapt) existing
tools to test a traditional software API library.  In one sense, this
is a less difficult end-user testing scenario than testing
spreadsheets or visual forms, in that the testing is directed by an
individual used to writing and thinking about software source code.
The concepts in modern automated software testing are most easily
understood by those who are also familiar with the structure and semantics of
conventional programming languages.  On the other hand, the system to
be tested is large, not a small user-developed program: ArcPy is
a modern, complex, library, comparable in complexity and size to
core language libraries.   ArcPy was also not written by the end-user,
or by any of the authors of this paper, nor have the authors received
any  assistance in the effort from Esri.

Automated testing systems more advanced than a simple hand-written loop generating 
a few random inputs to a handful of functions, or more complicated to 
use than a fully push-button system are often considered too difficult 
for practical use even by software developers or software QA staff \cite{ISSRE}.
In fact, in the experience of the second author of this paper (an
academic software testing researcher), even ``push-button'' tools for
automated testing are often difficult for expert users to install, apply, and
configure \cite{AMAI,CFV08,ISSRE}.  Such tools typically do not approach the ease-of-use seen
in commercial static analysis tools \cite{Coverity,Klocwork,CodeSonar}.  One goal of this work
has been to mature the TSTL language and toolchain so Python
programmers from all backgrounds can easily apply it to their
automated testing problems.

The second major contribution of this paper is therefore a presentation of an
approach to automated testing that has been chosen by a GIS analyst, not a
software developer or testing researcher.  Moreover, we present this
paper as a proof-of-concept that modern automated testing, even in a
highly interactive, non-push-button form, can be used by a motivated
domain expert, with the support of  a domain-specific language
\cite{Fow10} and a set of tools for generating, analyzing, and replaying tests.


