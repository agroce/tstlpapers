\section{Introduction}

It has long been understood that effective automated testing often requires
test reduction \cite{DD,MinUnit,TCminim,ICSEDiff} to produce useful tests.  In fact, test reduction is
now standard practice in industrial testing tools such as Mozilla's
{\tt jsfunfuzz} \cite{jsfunfuzz,jsfunfuzz2,lithium}.\footnote{Approaches that
  optimize for short tests \cite{SoftBET,FA11} may not require reduction, but random
  testing \cite{RandFormal,HamletOnly}, model-checking
  \cite{Gastin04minimizationof}, and symbolic execution \cite{issta14}
  can all benefit.}  However, simply reducing the length of a test
does not produce true semantic simplicity.  There may be many
1-minimal\footnote{No
  single component of a 1-minimal/delta-debugged \cite{DD} test can be removed without
  causing the test to pass.} tests
that present different variations of a single fault.  Far too often,
reading more than one of these tests provides no
additional information on the fault.

Consider the three 1-minimal tests in Figure
\ref{threetests}.  These tests are very similar, and all result
in an unbalanced AVL tree (due to a missing call to {\tt rebalance} in
{\tt delete}).  However, the tests are syntactically different,
and a testing system that collects failing tests will present all
three of these tests to a user.  In this paper we propose to go beyond test reduction
and convert all three of these
tests into a single, \emph{normalized} form that preserves failure
while deemphasizing accidental aspects of each test, such as
particular integer values and variable names, and ordering of steps.
%Unlike delta-debugging, this concept applies to test generation
%methods that produce 1-minimal tests.

Figure \ref{normalgen} shows the result of applying our \emph{test
  normalization} algorithm to the three tests in Figure
\ref{threetests}, and then applying our \emph{test
  generalization} algorithm to the normalized test.  \emph{All
  three tests normalize to the same test}.  Normalization is
enabled by a term rewriting algorithm \cite{term2,term1} that operates
on the level of test actions, and is thus language-agnostic:
it works by successively rewriting tests into ``simpler''
versions that preserve failure and are likely to retain the
underlying cause of the failure. Many
different reduced tests therefore normalize to the same form.
Unlike delta-debugging, normalization applies even to 1-minimal tests,
and often provides further reduction beyond the level of 1-minimality.

The test also includes comments, produced by our
\emph{generalization} \cite{SmartCheck} algorithm, indicating what
about the test can be changed while preserving the property that
the test fails.  Generalization uses automated experiments to discover
a semantic neighborhood of failng tests.  E.g.,
the value 1 assigned to {\tt int0} in step 0 is not essential.  It
could be changed to any value in the range 5-20.  Similarly, the exact ordering of many steps in the test
is inessential.  Finally, in step 9, instead of using the existing
value of {\tt int1} (4), a fresh assignment could be inserted before
the {\tt delete} call, setting {\tt int1} to 3 instead.  Changing any
of these aspects of the test (one at a time)
will preserve failure.  Generalization shows 
the user how a failure represents  a
\emph{family} of similar failing tests.

Combining normalization and generalization avoids common problems
with understanding automatically generated tests.  For instance,
when a large integer appears in a test, the question
arises --- is this value important, or just a random number of
no significance \cite{MakeMost}?  Large
values in a normalized test are always essential, because normalization includes value minimization.
Without generalization, however, it would be
easy to assume all \emph{small} numeric values in normalized
tests are accidental.  Generalization allows users to
distinguish actually essential small values.

Normalization is not yet a complete solution to the problem of identifying
distinct faults (e.g., our algorithms do not apply to complex custom
test generators such as Csmith \cite{csmith} or {\tt jsfunfuzz}
\cite{jsfunfuzz}), but it is often highly effective.  Running 100,000
tests (of length 100) on the faulty AVL tree produces 860 failing tests with no duplicates.  Normalizing these reduces the number of
distinct failing tests to just 22.  Ideally \emph{all} failures
due to the same fault in the SUT (Software Under Test) would normalize
to a single, representative test.  We aim to
\emph{approximate} such a canonical form for faults.  Figure \ref{diffnorm},
in Section \ref{formalexample}, shows an AVL tree test for this fault that
normalizes differently.  
%The structure of the {\tt delete} fault results in an
%unusually poor effectiveness for normalization. 
 In experiments with 82 AVL tree faults,
the mean number of distinct failures after normalization for 1,000
tests was just 3.1 (with median 2). 
%This fault, in contrast, produced 18
%distinct failures.  
%Determining that the failure in Figure
%\ref{diffnorm} (or one of the similarly structured other 20 failures)
%is due to the same fault as the failure in Figure \ref{normalgen}
%should be much less difficult than performing the same task over many hundreds of failures with much more extreme variation. 

The contributions of this paper are 1) the idea of test normalization and
generalization as key steps towards a goal of
``one test to rule them all'' (per fault), 2) algorithms for
normalization and generalization that make use of the abstract
interface for testing provided by the TSTL \cite{tstl,NFM15,ISSTA15,tstlsttt}
domain-specific language (DSL) \cite{Fow10}, and 3)
experimental results showing the value of these ideas.  Normalization frequently provides significant additional test length
reduction for complex SUTs, and can reduce
the set of failures to be examined by more than an order of
magnitude.  Normalization and generalization have also been useful in
understanding complicated tests for a variety of real-world software
systems.

\begin{figure}[t]
{\scriptsize
\raggedright
{\bf Test \#1}\hspace{.7in}{\bf Test \#2} \hspace{0.65in}{\bf Test \#3}
\begin{verbatim}
avl0 = avl.AVLTree()   int0 = 14              avl1 = avl.AVLTree()
int0 = 4               avl0 = avl.AVLTree()   int3 = 18 
int2 = 13              int2 = 13              avl1.insert(int3) 
int3 = 7               int1 = 15              int0 = 5 
avl0.insert(int2)      avl0.insert(int1)      int3 = 12 
avl0.insert(int3)      int1 = 11              avl1.insert(int0) 
int1 = 15              avl0.insert(int2)      int0 = 15 
avl0.insert(int1)      avl0.insert(int0)      avl1.insert(int0) 
avl0.insert(int0)      avl0.insert(int1)      avl1.insert(int3) 
avl0.delete(int2)      avl0.delete(int0)      int1 = 15 
                                              avl1.delete(int1) 
\end{verbatim}
}
%\vspace{-0.2in}
\caption {{Three random tests for one fault.}}
\label{threetests}
%\vspace{-0.15in}
\end{figure}

\begin{figure}[t]
{\scriptsize
\begin{code}
\textcolor{black!60}{\#[}
int0 = 1                              \textcolor{black!60}{\# STEP 0}
\textcolor{black!60}{\#  or int0 = 5 }
\textcolor{black!60}{\#   - int0 = 20} 
\textcolor{black!60}{\#  swaps with step 4}
int1 = 3                              \textcolor{black!60}{\# STEP 1}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 6}
avl0 = avl.AVLTree()                  \textcolor{black!60}{\# STEP 2}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 3}
\textcolor{black!60}{\#[}
int0 = 2                              \textcolor{black!60}{\# STEP 4}
\textcolor{black!60}{\#  swaps with step 0}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 5}
\textcolor{black!60}{\#] (steps in [] can be in any order)}
int1 = 4                              \textcolor{black!60}{\# STEP 6}
\textcolor{black!60}{\#  or int1 = 5 }
\textcolor{black!60}{\#   - int1 = 20} 
\textcolor{black!60}{\#  swaps with step 1}
avl0.insert(int1)                     \textcolor{black!60}{\# STEP 7}
avl0.insert(int0)                     \textcolor{black!60}{\# STEP 8}
avl0.delete(int1)                     \textcolor{black!60}{\# STEP 9}
\textcolor{black!60}{\#  or (}
\textcolor{black!60}{\#      int1 = 3  ;}
\textcolor{black!60}{\#      avl0.delete(int1) }
\textcolor{black!60}{\#     )}
\end{code}
}
\caption{{Normalization and generalization for all three tests.
  Lines beginning with \# are comments in Python, used for annotations.}}
\label{normalgen}
\end{figure}

